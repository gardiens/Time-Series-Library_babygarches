{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the usual import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Chose your args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Chose his args \n",
    "\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # basic config\n",
    "        self.task_name = 'long_term_forecast'\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'TEST'\n",
    "        self.model = 'FEDformer'\n",
    "        self.num_itr=0\n",
    "        # data loader\n",
    "        self.data = 'NTU'\n",
    "        self.root_path = './dataset/NTU_RGB+D/'\n",
    "        self.data_path = 'numpyed/'\n",
    "        self.features = 'M'\n",
    "        self.target = 'OT'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "\n",
    "        # forecasting task\n",
    "        self.seq_len = 16\n",
    "        self.label_len = 30\n",
    "        self.pred_len = 35\n",
    "        self.seasonal_patterns = 'Monthly'\n",
    "\n",
    "        # inputation task\n",
    "        self.mask_rate = 0.25\n",
    "\n",
    "        # anomaly detection task\n",
    "        self.anomaly_ratio = 0.25\n",
    "\n",
    "        # model define\n",
    "        self.top_k = 5\n",
    "        self.num_kernels = 6\n",
    "        self.enc_in = 75\n",
    "        self.dec_in = 75\n",
    "        self.c_out = 75\n",
    "        self.d_model = 512\n",
    "        self.n_heads = 8\n",
    "        self.e_layers = 2\n",
    "        self.d_layers = 1\n",
    "        self.d_ff = 2048\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 3\n",
    "        self.distil = True\n",
    "        self.dropout = 0.1\n",
    "        self.embed = 'timeNTU'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "\n",
    "        # optimization\n",
    "        self.num_workers = 10\n",
    "        self.itr = 1\n",
    "        self.train_epochs = 14\n",
    "        self.batch_size = 256\n",
    "        self.patience = 3\n",
    "        self.learning_rate = 10**(-3)\n",
    "        self.des = 'Exp'\n",
    "        self.loss = 'MSE'\n",
    "        self.lradj = 'sem_constant'\n",
    "        self.use_amp = False\n",
    "\n",
    "        # GPU\n",
    "        self.use_gpu = False\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0'\n",
    "\n",
    "        # de-stationary projector params\n",
    "        self.p_hidden_dims = [128, 128]\n",
    "        self.p_hidden_layers = 2\n",
    "\n",
    "        # NTU_RG\n",
    "        self.get_time_value = 1\n",
    "        self.get_cat_value = 0\n",
    "        self.ii=0\n",
    "        self.preprocess=1\n",
    "        self.split_train_test=\"action\"\n",
    "        self.num_itr=0\n",
    "        self.augment=False\n",
    "        self.start_checkpoint=False\n",
    "args=Args()\n",
    "from utils.constantes import get_settings\n",
    "setting=get_settings(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#*  args used for real script\n",
    "from utils.constantes import get_settings\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        # basic config\n",
    "        self.task_name = 'long_term_forecast'\n",
    "        self.is_training = 0\n",
    "        self.model_id = 'Usable'\n",
    "        self.model = 'FEDformer'\n",
    "        self.num_itr=0\n",
    "        # data loader\n",
    "        self.data = 'NTU'\n",
    "        self.root_path = './dataset/NTU_RGB+D/'\n",
    "        self.data_path = 'numpyed/'\n",
    "        self.features = 'M'\n",
    "        self.target = 'OT'\n",
    "        self.freq = 'h'\n",
    "        self.checkpoints = './checkpoints/'\n",
    "\n",
    "        # forecasting task\n",
    "        self.seq_len = 16\n",
    "        self.label_len = 32\n",
    "        self.pred_len = 32\n",
    "        self.seasonal_patterns = 'Monthly'\n",
    "\n",
    "        # inputation task\n",
    "        self.mask_rate = 0.25\n",
    "\n",
    "        # anomaly detection task\n",
    "        self.anomaly_ratio = 0.25\n",
    "\n",
    "        # model define\n",
    "        self.top_k = 5\n",
    "        self.num_kernels = 6\n",
    "        self.enc_in = 75\n",
    "        self.dec_in = 75\n",
    "        self.c_out = 75\n",
    "        self.d_model = 512\n",
    "        self.n_heads = 8\n",
    "        self.e_layers = 2\n",
    "        self.d_layers = 1\n",
    "        self.d_ff = 2048\n",
    "        self.moving_avg = 25\n",
    "        self.factor = 3\n",
    "        self.distil = True\n",
    "        self.dropout = 0.1\n",
    "        self.embed = 'timeNTU'\n",
    "        self.activation = 'gelu'\n",
    "        self.output_attention = False\n",
    "\n",
    "        # optimization\n",
    "        self.num_workers = 10\n",
    "        self.itr = 1\n",
    "        self.train_epochs = 14\n",
    "        self.batch_size = 256\n",
    "        self.patience = 3\n",
    "        self.learning_rate = 10**(-3)\n",
    "        self.des = 'Exp'\n",
    "        self.loss = 'MSE'\n",
    "        self.lradj = 'sem_constant'\n",
    "        self.use_amp = False\n",
    "\n",
    "        # GPU\n",
    "        self.use_gpu = False\n",
    "        self.gpu = 0\n",
    "        self.use_multi_gpu = False\n",
    "        self.devices = '0'\n",
    "\n",
    "        # de-stationary projector params\n",
    "        self.p_hidden_dims = [128, 128]\n",
    "        self.p_hidden_layers = 2\n",
    "\n",
    "        # NTU_RG\n",
    "        self.get_time_value = 1\n",
    "        self.get_cat_value = 0\n",
    "        self.ii=0\n",
    "        self.preprocess=1\n",
    "        self.split_train_test=\"action\"\n",
    "        self.start_checkpoint=False\n",
    "        self.augment=False\n",
    "        self.no_test=False\n",
    "args=Args()\n",
    "\n",
    "setting=get_settings(args)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Fetch data on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - data path\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a data path or a root path\n",
    "import os\n",
    "root_path='./dataset/NTU_RGB+D/'\n",
    "data_path_npy=os.path.join(root_path,'numpyed/')\n",
    "data_path_skel=os.path.join(root_path,'raw/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path of a .skeleton\n",
    "path_skeleton=\"dataset/NTU_RGB+D/raw/S001C001P001R001A001.skeleton\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get a .csv with the most important features (Data Set preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Value to test your data fast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NTU_RGB\n",
    "path_summary='./dataset/NTU_RGB+D/summary_NTU/summary_NTU.csv'\n",
    "path_avant_dataset='./dataset/NTU_RGB+D/summary_NTU/liste_NTU_skeleton_4.csv'\n",
    "categorical=['nbodys', 'filename', 'actor', 'acti', 'camera', 'scene', 'repet','njoints']\n",
    "particulier=['nb_frames', 'debut_frame', 'num_body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "2. for \"test\" sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of a skeleton\n",
    "path_skeleton=\"dataset/NTU_RGB+D/raw/S001C001P001R001A001.skeleton\"\n",
    "skeleton_name=\"S001C001P001R001A001\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Get the big .csv where you will get the right data after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NTU_RGB.utils_dataset import summary_csv_NTU\n",
    "\n",
    "df,path=summary_csv_NTU() #*  really slow operation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.0 The dataframe where we will get the most important information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NTU_RGB.utils_dataset import preprocess_csv_RGB_to_skeletondf\n",
    "seq_len=30\n",
    "out_len=30\n",
    "df,path=preprocess_csv_RGB_to_skeletondf(seq_len=seq_len,out_len=out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Get a sample of data that will be used inside NTU_RGB ( it is  data_set.liste_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NTU_RGB.utils_dataset import data_rentrer_dans_DATASET_NTU\n",
    "seq_len=32\n",
    "out_len=64\n",
    "df=data_rentrer_dans_DATASET_NTU(seq_len=seq_len,out_len=out_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a sample of skeleton .npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_skeleton=\"dataset/NTU_RGB+D/numpyed/S001C001P001R001A001.skeleton.npy\"\n",
    "import numpy as np\n",
    "data = np.load(path_skeleton,allow_pickle=True).item()\n",
    "# we want usually data['skel_body0'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and model runs (FED/Auto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Récupération du dataset et data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- récupération du dataset et du dataloader de NTU_RGB (suit l'args précédement défini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_provider.data_factory import data_provider\n",
    "args=Args()\n",
    "data_set, data_loader=data_provider(args,flag=\"train\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entry=data_set.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entry technical detail when you get back on data_set ._ Getitem __ (0)\n",
    "\"\"\"\n",
    "Entry is in the form:\n",
    "(input_frames, nb_channels = 75)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recovery of an item from data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "usual method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(batch_x, batch_y, batch_x_mark, batch_y_mark)=enumerate(data_loader).__next__()[1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "alternative but faster method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_name=\"S001C001P001R001A001\"\n",
    "entry=data_set.get_data_from_sample_name(name_skeleton=sample_name,num_body=0) #* Attention au numéro du body!\n",
    "entry_batch=data_set.get_input_model(entry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Run of the model: Fed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Setup of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.FEDformer import *\n",
    "network=Model(args)\n",
    "network.float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-recuperation of a dataset entrance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical detail of the input of the Data_loader model/\n",
    "\"\"\"\n",
    "It is in shape: batch_x, batch_y, batch_x_mark, batch_y_mark\n",
    "\n",
    "and batch_x is in shape\n",
    "\n",
    "(nb_batch  Input_len, nb_channel)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch recovery\n",
    "from data_provider.data_factory import data_provider\n",
    "args=Args()\n",
    "data_set, data_loader=data_provider(args,flag=\"train\") \n",
    "\n",
    "(batch_x, batch_y, batch_x_mark, batch_y_mark)=enumerate(data_loader).__next__()[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- output of the Fedformers model (uses the front data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=network(batch_x.float(), batch_x_mark.float(),None, batch_y_mark.float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Technical detail of the Fedformers outing\n",
    "\"\"\" \n",
    "y est de la forme: (batch_size, pred_len, nb_channel)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run of exp_long_term_forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usual setings to take all at the top of the jupyter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model launch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast\n",
    "Exp=Exp_Long_Term_Forecast\n",
    "\n",
    "exp = Exp(args)\n",
    "exp.train(setting)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Technical detail to use Plot_skeletons:\n",
    "\"\"\"\n",
    "To visualize a skeleton, the Skeleton array must be in shape: \\\n",
    "-[nb_joints, nb_dimension (3), nb_frames]\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example of input for plot skeletons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NTU_RGB.utils_NTU import read_xyz\n",
    "path_skeleton=\"dataset/NTU_RGB+D/raw/S001C001P001R001A001.skeleton\"\n",
    "skeleton = read_xyz(path_skeleton)\n",
    "skeleton.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot a video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get a data path or a root path\n",
    "import os\n",
    "root_path='./dataset/NTU_RGB+D/'\n",
    "data_path_npy=os.path.join(root_path,'numpyed/')\n",
    "data_path_skel=os.path.join(root_path,'raw/')\n",
    "skeleton=\"S001C001P001R001A001.skeleton\"\n",
    "path_skeleton=os.path.join(data_path_skel,skeleton)\n",
    "\n",
    "print(path_skeleton)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters of the plot\n",
    "num_body=0\n",
    "# Check the number of body, if it is greater than 0 we outputs the skeleton num_body of the scene, else everything if num_body=-1\n",
    "save_name=\"example\"\n",
    "path_folder_save=\"./videos/\" # where we store the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NTU_RGB.plot_skeleton import plot_skeleton\n",
    "plot_skeleton(path_skeleton=path_skeleton,\n",
    "              save_name=save_name,\n",
    "              path_folder_save=path_folder_save,\n",
    "              num_body=num_body)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
